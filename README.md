# ğŸ§  Recollect AI â€” Persistent Memory RAG Assistant
ğŸš€ **Live Demo:** https://recollect-ai-nine.vercel.app/
Recollect AI is a full-stack Retrieval-Augmented Generation (RAG) application designed to act as a personal AI assistant with persistent long-term memory.  
Unlike traditional chatbots that forget everything between sessions, Recollect AI extracts, stores, and retrieves user-specific facts across conversations using a vector database.

---

## ğŸš€ Key Features

### ğŸ§© Persistent Long-Term Memory
- Extracts personal facts such as name, age, hobbies, preferences, and education from conversations
- Stores extracted facts in a dedicated Pinecone namespace for long-term retrieval
- Enables the assistant to answer questions like â€œWhat is my name?â€ or â€œWhich game do I love?â€ across sessions

### ğŸ“„ Context-Aware PDF Chat
- Upload and chat with multiple PDFs independently
- Uses metadata filtering ($eq) to ensure information from one document never leaks into another
- Ideal for resumes, research papers, or study material

### ğŸ§  Smart Chat Core
- Centralized chatbot logic handles:
  - General chat
  - PDF-based queries
  - Website ingestion
  - Memory lookups
- Automatically decides when to retrieve memory vs when to answer directly

### ğŸŒ Dynamic Environment Detection
- Automatically detects whether the app is running on:
  - localhost
  - Render / Vercel (production)
- Routes API calls accordingly without manual changes

### ğŸ”¢ Token-Optimized Processing
- Uses tiktoken for accurate token counting
- Splits long documents into optimal chunks with overlap
- Prevents context window overflow while maintaining answer quality

---

## ğŸ› ï¸ Tech Stack

Frontend
- HTML5
- CSS3
- Vanilla JavaScript

Backend
- Python 3.8+
- FastAPI

LLM
- OpenAI GPT-4o-mini (Chat Completions & Embeddings)

Vector Database
- Pinecone (Serverless)

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Prerequisites
- Python 3.8 or higher
- OpenAI API Key
- Pinecone API Key & Index

### 2ï¸âƒ£ Environment Variables
Create a `.env` file inside the `backend/` directory:

OPENAI_API_KEY=your_openai_api_key  
PINECONE_API_KEY=your_pinecone_api_key  
INDEX_NAME=recollect-ai  
PINECONE_REGION=us-west-2  

### 3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


## ğŸ“‚ Project Structure

```text
PREDUSK TECHNOLOGY
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                  # API endpoints and route definitions
â”‚   â”‚   â””â”€â”€ routes.py         # Main router for chat and file handling
â”‚   â”œâ”€â”€ config/               # System-level configuration
â”‚   â”‚   â””â”€â”€ settings.py       # Environment variable management
â”‚   â”œâ”€â”€ core/                 # Core RAG processing logic
â”‚   â”‚   â””â”€â”€ ingest.py         # Document ingestion and fact extraction
â”‚   â”œâ”€â”€ llm/                  # OpenAI client configuration
â”‚   â”‚   â””â”€â”€ openai_client.py
â”‚   â”œâ”€â”€ utils/                # Non-business logic helper functions
â”‚   â”œâ”€â”€ vectorstore/          # Pinecone integration and metadata filters
â”‚   â”‚   â””â”€â”€ pinecone_store.py
â”‚   â”œâ”€â”€ .env                  # Local environment secrets
â”‚   â”œâ”€â”€ app.py                # Primary application entry point
â”‚   â””â”€â”€ main.py               # Chatbot core (handles websites & general queries)
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html             # UI structure
    â”œâ”€â”€ script.js              # Client-side logic and API communication
    â””â”€â”€ style.css              # Application styling
```

### 4ï¸âƒ£ Run the Application

Backend:
python -m uvicorn backend.app:app --reload

Frontend:
Serve the `frontend/` directory using VS Code Live Server or any static file server

---

## ğŸ¤– How It Works

### ğŸ” Chat Flow
1. User sends a query
2. Query is converted into embeddings
3. Pinecone performs semantic search on:
   - Memory namespace
   - Document namespace
4. Relevant context is assembled
5. Final prompt is sent to the LLM
6. Response is returned to the user

### ğŸ§  Memory Extraction
- Uses rule-based logic to detect personal facts
- Stores extracted facts as vectors
- Can be upgraded to LLM-based extraction



## ğŸ“§ Contact
Swastik 
GitHub: https://github.com/SwastiksGautam
Linkdin: https://www.linkedin.com/in/swastiksharma1/
